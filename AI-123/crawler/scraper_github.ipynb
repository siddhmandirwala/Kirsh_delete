{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f276df-511b-4986-911f-022ae71db409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import tempfile\n",
    "import uuid\n",
    "from typing import Dict\n",
    "from loguru import logger\n",
    "from pymongo import MongoClient, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61d76182-4302-4899-b190-8bb9e38773be",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_URI = \"mongodb://localhost:27017/\"\n",
    "DATABASE_NAME = \"github_scraper\"\n",
    "COLLECTION_NAME = \"repositories\"\n",
    "\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DATABASE_NAME]\n",
    "collection = db[COLLECTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32f8d3d0-7a1c-404e-88d3-9d51384b5c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GithubCrawler:\n",
    "    def __init__(self, ignore=(\".git\", \".toml\", \".lock\", \".png\")) -> None:\n",
    "        self._ignore = ignore\n",
    "\n",
    "    def extract(self, link: str, user: Dict) -> None:\n",
    "        \"\"\"Extracts content from a GitHub repository and saves it to MongoDB.\"\"\"\n",
    "        # Check if repository already exists\n",
    "        if collection.find_one({\"link\": link}):\n",
    "            logger.info(f\"Repository already exists in the database: {link}\")\n",
    "            return\n",
    "\n",
    "        logger.info(f\"Starting to scrape GitHub repository: {link}\")\n",
    "        repo_name = link.rstrip(\"/\").split(\"/\")[-1]\n",
    "        local_temp = tempfile.mkdtemp()\n",
    "\n",
    "        try:\n",
    "            # Clone the repository\n",
    "            subprocess.run([\"git\", \"clone\", link], check=True, cwd=local_temp)\n",
    "\n",
    "            # Get the path of the cloned repository\n",
    "            repo_path = os.path.join(local_temp, os.listdir(local_temp)[0])\n",
    "\n",
    "            # Build the content tree\n",
    "            tree = {}\n",
    "            for root, _, files in os.walk(repo_path):\n",
    "                rel_dir = root.replace(repo_path, \"\").lstrip(\"/\")\n",
    "                if any(rel_dir.startswith(pattern) for pattern in self._ignore):\n",
    "                    continue\n",
    "\n",
    "                for file in files:\n",
    "                    if any(file.endswith(pattern) for pattern in self._ignore):\n",
    "                        continue\n",
    "                    file_path = os.path.join(rel_dir, file)\n",
    "                    try:\n",
    "                        with open(os.path.join(root, file), \"r\", errors=\"ignore\") as f:\n",
    "                            tree[file_path] = f.read().strip()\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Failed to read file {file_path}: {e}\")\n",
    "\n",
    "            # Save the repository data to MongoDB\n",
    "            repo_data = {\n",
    "                \"_id\": str(uuid.uuid4()),\n",
    "                \"name\": repo_name,\n",
    "                \"link\": link,\n",
    "                \"content\": tree,\n",
    "                \"platform\": \"github\",\n",
    "                \"author_id\": user[\"id\"],\n",
    "                \"author_full_name\": user[\"full_name\"],\n",
    "            }\n",
    "            collection.insert_one(repo_data)\n",
    "            logger.info(f\"Repository {repo_name} saved successfully.\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            logger.error(f\"Failed to clone repository: {e}\")\n",
    "        except errors.PyMongoError as e:\n",
    "            logger.error(f\"Failed to save data to MongoDB: {e}\")\n",
    "        finally:\n",
    "            # Cleanup temporary directory\n",
    "            shutil.rmtree(local_temp)\n",
    "\n",
    "        logger.info(f\"Finished scraping GitHub repository: {link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c03fc06d-b6b1-454a-bf42-069862bf3c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-05 22:44:44.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mextract\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mStarting to scrape GitHub repository: https://github.com/ros-controls/ros2_controllers\u001b[0m\n",
      "Cloning into 'ros2_controllers'...\n",
      "\u001b[32m2024-12-05 22:44:45.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mextract\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mRepository ros2_controllers saved successfully.\u001b[0m\n",
      "\u001b[32m2024-12-05 22:44:45.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mextract\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mFinished scraping GitHub repository: https://github.com/ros-controls/ros2_controllers\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "crawler = GithubCrawler()\n",
    "test_user = {\"id\": str(uuid.uuid4()), \"full_name\": \"Test User\"}\n",
    "test_link = \"https://github.com/ros-controls/ros2_controllers\"\n",
    "\n",
    "crawler.extract(link=test_link, user=test_user)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
